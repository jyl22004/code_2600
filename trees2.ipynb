{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd484f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ISLP import load_data, confusion_table\n",
    "from ISLP.models import ModelSpec as MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss)\n",
    "from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RF,\n",
    "      GradientBoostingRegressor as GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560b9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "Auto = load_data('Auto')\n",
    "Auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f558da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also impute the missing values of \"horsepower\" as we did previously\n",
    "\n",
    "Auto['horsepower'].replace('?','104',inplace=True)\n",
    "Auto['horsepower'] = pd.to_numeric(Auto['horsepower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the numeric variables in the data to predict mpg\n",
    "\n",
    "X = Auto[['cylinders','displacement','horsepower','weight','acceleration','year','origin']]\n",
    "y = Auto['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb79ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=314,\n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True) \n",
    "Train = pd.merge_ordered(X_train,y_train,left_on=X_train.index,right_on=y_train.index).drop(columns=['key_0'])\n",
    "Test = pd.merge_ordered(X_test,y_test,left_on=X_test.index,right_on=y_test.index).drop(columns=['key_0'])\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad19d0f",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2862b2",
   "metadata": {},
   "source": [
    "### An Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "# Documentation: https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "gbm_auto = GBR(learning_rate=0.5,\n",
    "               n_estimators=50,\n",
    "               max_depth=5,\n",
    "               random_state=314)\n",
    "gbm_auto.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE on test set\n",
    "\n",
    "# Get predictions on test\n",
    "y_hat_gbm = gbm_auto.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_gbm = np.mean((y_test - y_hat_gbm)**2)\n",
    "print('test mse: ',mse_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881adb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can actually plot the \"progress\" of a GBM\n",
    "\n",
    "test_error = np.zeros_like(gbm_auto.train_score_)\n",
    "for idx, y_ in enumerate(gbm_auto.staged_predict(X_test)):\n",
    "   test_error[idx] = np.mean((y_test - y_)**2)\n",
    "\n",
    "plot_idx = np.arange(gbm_auto.train_score_.shape[0])\n",
    "ax = subplots(figsize=(8,8))[1]\n",
    "ax.plot(plot_idx,\n",
    "        gbm_auto.train_score_,\n",
    "        'b',\n",
    "        label='Training')\n",
    "ax.plot(plot_idx,\n",
    "        test_error,\n",
    "        'r',\n",
    "        label='Test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5343f",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Note that a feature importance list from a RF model is generally more robust than one from a GBM, but this is still helpful for explainability purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63693fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance list\n",
    "feature_names = list(X_train.columns)\n",
    "feature_imp = pd.DataFrame(\n",
    "    {'importance':gbm_auto.feature_importances_},\n",
    "    index=feature_names)\n",
    "feature_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca9ddf",
   "metadata": {},
   "source": [
    "## Single Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lift chart to assess a single model (thank you ChatGPT)\n",
    "\n",
    "def plot_regression_lift_chart(y_true, y_preds, n_bins=10):\n",
    "    \"\"\"\n",
    "    Plots a lift chart for a regression model.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Array-like of true continuous values.\n",
    "    - y_preds: Array-like of predicted values.\n",
    "    - n_bins: Number of bins to use for the lift chart.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame with true values and predicted values\n",
    "    data = pd.DataFrame({'y_true': y_true, 'y_preds': y_preds})\n",
    "    \n",
    "    # Sort the DataFrame by predicted values\n",
    "    data = data.sort_values(by='y_preds', ascending=False)\n",
    "\n",
    "    # Create bins based on predicted values\n",
    "    data['bin'] = pd.qcut(data['y_preds'], n_bins, labels=False)\n",
    "\n",
    "    # Calculate lift\n",
    "    lift_data = data.groupby('bin').agg(\n",
    "        total_count=('y_true', 'count'),\n",
    "        actual_mean=('y_true', 'mean'),\n",
    "        predicted_mean=('y_preds', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate expected mean (mean of actual values)\n",
    "    expected_mean = data['y_true'].mean()\n",
    "    \n",
    "    # Calculate lift\n",
    "    lift_data['lift'] = lift_data['actual_mean'] / expected_mean\n",
    "\n",
    "    # Plot the lift chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(lift_data['bin'], lift_data['lift'], marker='o', label='Lift')\n",
    "    plt.axhline(y=1, color='r', linestyle='--', label='Random Guessing Lift (1)')\n",
    "    plt.title('Lift Chart for Regression Model')\n",
    "    plt.xlabel('Bins')\n",
    "    plt.ylabel('Lift')\n",
    "    plt.xticks(lift_data['bin'])\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f32f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_lift_chart(y_test, y_hat_gbm, n_bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143becb3",
   "metadata": {},
   "source": [
    "### A Better Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db41dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a better model\n",
    "\n",
    "gbm_auto_baseline = GBR(learning_rate=0.01,\n",
    "                        n_estimators=500,\n",
    "                        max_depth=5,\n",
    "                        random_state=314)\n",
    "gbm_auto_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9246b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE on test set\n",
    "\n",
    "# Get predictions on test\n",
    "y_hat_gbm_baseline = gbm_auto_baseline.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_gbm_baseline = np.mean((y_test - y_hat_gbm_baseline)**2)\n",
    "print('test mse: ',mse_gbm_baseline)\n",
    "print('previous test mse: ',mse_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the \"progress\" look like?\n",
    "\n",
    "test_error = np.zeros_like(gbm_auto_baseline.train_score_)\n",
    "for idx, y_ in enumerate(gbm_auto_baseline.staged_predict(X_test)):\n",
    "   test_error[idx] = np.mean((y_test - y_)**2)\n",
    "\n",
    "plot_idx = np.arange(gbm_auto_baseline.train_score_.shape[0])\n",
    "ax = subplots(figsize=(8,8))[1]\n",
    "ax.plot(plot_idx,\n",
    "        gbm_auto_baseline.train_score_,\n",
    "        'b',\n",
    "        label='Training')\n",
    "ax.plot(plot_idx,\n",
    "        test_error,\n",
    "        'r',\n",
    "        label='Test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576724b",
   "metadata": {},
   "source": [
    "## Double Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a double lift chart to compare two models\n",
    "## Note that this needed a LOT of prompt engineering in ChatGPT, and still needed manual edits.\n",
    "\n",
    "def plot_double_lift_chart(y_true, y_pred_model1, y_pred_model2,\n",
    "                           model1_name='Model A', model2_name='Model B',\n",
    "                           n_bins=10):\n",
    "    \"\"\"\n",
    "    Plots a double lift chart comparing two regression models, \n",
    "    where bins are sorted by the ratio of Model 1 to Model 2 predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Array-like of true continuous values.\n",
    "    - y_pred_model1: Array-like of predicted values from Model 1.\n",
    "    - y_pred_model2: Array-like of predicted values from Model 2.\n",
    "    - model1_name, model2_name: Names to display in the legend.\n",
    "    - n_bins: Number of quantile bins to use for the lift chart.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build combined dataframe\n",
    "    data = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'pred1': y_pred_model1,\n",
    "        'pred2': y_pred_model2\n",
    "    })\n",
    "\n",
    "    # Avoid division by zero\n",
    "    data = data[data['pred2'] != 0]\n",
    "\n",
    "    # Compute ratio of predictions\n",
    "    data['ratio'] = data['pred1'] / data['pred2']\n",
    "\n",
    "    # Sort descending by ratio\n",
    "    data = data.sort_values(by='ratio', ascending=False)\n",
    "\n",
    "    # Create quantile bins based on the ratio\n",
    "    data['bin'] = pd.qcut(data['ratio'], n_bins, labels=False, duplicates='drop')\n",
    "\n",
    "    # Overall means for normalization\n",
    "    overall_mean_true = data['y_true'].mean()\n",
    "    overall_mean_pred1 = data['pred1'].mean()\n",
    "    overall_mean_pred2 = data['pred2'].mean()\n",
    "\n",
    "    # Aggregate lift stats for each bin\n",
    "    lift_data = data.groupby('bin').agg(\n",
    "        actual_mean=('y_true', 'mean'),\n",
    "        model1_mean=('pred1', 'mean'),\n",
    "        model2_mean=('pred2', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute model error in each bin\n",
    "    lift_data['model1_lift'] = lift_data['model1_mean'] / lift_data['actual_mean']\n",
    "    lift_data['model2_lift'] = lift_data['model2_mean'] / lift_data['actual_mean']\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(lift_data['bin'], lift_data['model1_lift'], marker='s', linestyle='-', linewidth=2, label=f'{model1_name} Predicted Lift')\n",
    "    plt.plot(lift_data['bin'], lift_data['model2_lift'], marker='^', linestyle='--', linewidth=2, label=f'{model2_name} Predicted Lift')\n",
    "\n",
    "    plt.axhline(y=1, color='red', linestyle=':', label='Baseline (Lift = 1)')\n",
    "    plt.title(f'Double Lift Chart by Ratio of {model1_name} / {model2_name}', fontsize=14)\n",
    "    plt.xlabel(f'Bins (sorted by {model1_name} / {model2_name} ratio)')\n",
    "    plt.ylabel('Lift (Mean / Overall Mean)')\n",
    "    plt.xticks(np.arange(0, lift_data.shape[0]))\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_double_lift_chart(y_test, y_hat_gbm, y_hat_gbm_baseline,\n",
    "                           model1_name='Initial', model2_name='Baseline',\n",
    "                           n_bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940be8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
